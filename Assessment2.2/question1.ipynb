{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_name_text(text_data):\n",
    "\n",
    "    # Initialize a list to store dictionaries\n",
    "    entries = []\n",
    "\n",
    "    # Extract the name and text part from each line\n",
    "    for line in text_data:\n",
    "        parts = line.split('/')\n",
    "        name = parts[2]\n",
    "        text = line.split(':', 1)[1].strip()\n",
    "        \n",
    "        # Create a dictionary for each entry\n",
    "        entry = {'Name': name, 'Text': text}\n",
    "        \n",
    "        # Append the dictionary to the list\n",
    "        entries.append(entry)\n",
    "\n",
    "    # Print the list of dictionaries\n",
    "    # for entry in entries:\n",
    "    #     print(entry)\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(text_file, entries):\n",
    "\n",
    "    if text_file == './spe.text':\n",
    "        pattern = r'spe(?=[\\s\\'s])'\n",
    "\n",
    "\n",
    "    # Initialize a new list to store filtered entries\n",
    "    filtered_entries = []\n",
    "\n",
    "    # Iterate through each entry in the list\n",
    "    for entry in entries:\n",
    "        if re.search(pattern, entry['Text'], re.IGNORECASE):\n",
    "            # If the condition is met, append the entry to the filtered list\n",
    "            filtered_entries.append(entry)\n",
    "\n",
    "    # Update the entries list with the filtered entries\n",
    "    entries = filtered_entries\n",
    "\n",
    "    # Print the updated list of dictionaries\n",
    "    # for entry in entries:\n",
    "    #     print(entry)\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_csv(entries):\n",
    "    # Specify the path for the CSV file\n",
    "    csv_file = 'output.csv'\n",
    "\n",
    "    # Write the contents of the list of dictionaries to the CSV file\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['Name', 'Text'])\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write each dictionary as a row in the CSV file\n",
    "        for entry in entries:\n",
    "            writer.writerow(entry)\n",
    "\n",
    "    print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pd():\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('output.csv')\n",
    "\n",
    "    df.drop_duplicates()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_dup_names(df):\n",
    "    names_df = df['Name'].drop_duplicates()\n",
    "\n",
    "    print(names_df.count())\n",
    "\n",
    "    names_list = []\n",
    "\n",
    "    for name in names_df:\n",
    "        names_list.append(name)\n",
    "\n",
    "    return names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_check():\n",
    "\n",
    "    with open('./2001.text', 'r',) as file:\n",
    "        \n",
    "        year_data = file.readlines()\n",
    "\n",
    "\n",
    "\n",
    "    names2001 = []\n",
    "\n",
    "    for line in year_data:\n",
    "        parts = line.split('/')\n",
    "        name = parts[2]\n",
    "        names2001.append(name)\n",
    "\n",
    "    return names2001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df_2001(names2001):\n",
    "\n",
    "    df_names_2001 = pd.DataFrame(names2001, columns=['Names'])\n",
    "    df_names_2001 = df_names_2001['Names'].drop_duplicates()\n",
    "\n",
    "    names_2001_list = []\n",
    "\n",
    "    for name in df_names_2001:\n",
    "        names_2001_list.append(name)\n",
    "\n",
    "    return names_2001_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_names(names_2001_list, names_list):\n",
    "\n",
    "    names_2001 = []\n",
    "\n",
    "    for name in names_list:\n",
    "        if name in names_2001_list:\n",
    "            names_2001.append(name)\n",
    "\n",
    "    \n",
    "    return names_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n",
      "150\n",
      "CSV file has been created successfully.\n",
      "105\n",
      "CSV file has been created successfully.\n",
      "11\n",
      "CSV file has been created successfully.\n",
      "100\n",
      "CSV file has been created successfully.\n",
      "37\n",
      "[('spe_df', {'perlingiere-d', 'rodrique-r', 'hodge-j', 'kaminski-v', 'lavorato-j', 'weldon-c', 'symes-k', 'hernandez-j', 'mann-k', 'geaccone-t', 'haedicke-m', 'sanchez-m', 'hyatt-k', 'lenhart-m', 'mclaughlin-e', 'steffes-j', 'holst-k', 'donoho-l', 'buy-r', 'meyers-a', 'scholtes-d', 'brawner-s', 'ermis-f', 'wolfe-j', 'taylor-m', 'parks-j', 'townsend-j', 'staab-t', 'phanis-s', 'donohoe-t', 'heard-m', 'rogers-b', 'tycholiz-b', 'gilbertsmith-d', 'swerzbin-m', 'corman-s', 'stclair-c', 'nemec-g', 'lokey-t', 'arora-h', 'scott-s', 'south-s', 'schoolcraft-d', 'hain-m', 'beck-s', 'whalley-g', 'martin-t', 'bailey-s', 'harris-s', 'schwieger-j', 'lucci-p', 'mckay-b', 'shackleton-s', 'cash-m', 'maggi-m', 'kuykendall-t', 'mckay-j', 'sager-e', 'carson-m', 'fossum-d', 'stepenovitch-j', 'presto-k', 'whalley-l', 'saibi-e', 'cuilla-m', 'blair-l', 'forney-j', 'motley-m', 'baughman-d', 'farmer-d', 'ybarbo-p', 'shively-h', 'keavey-p', 'fischer-m', 'causholli-m', 'grigsby-m', 'arnold-j', 'shapiro-r', 'hyvl-d', 'ring-a', 'keiser-k', 'sanders-r', 'pereira-s', 'lay-k', 'horton-s', 'kean-s', 'smith-m', 'tholt-j', 'stokley-c', 'rapp-b', 'solberg-g', 'dorland-c', 'gay-r', 'hayslett-r', 'semperger-c', 'dean-c', 'thomas-p', 'derrick-j', 'williams-w3', 'lokay-m', 'hendrickson-s', 'panus-s', 'love-p', 'ward-k', 'crandell-s', 'slinger-r', 'white-s', 'whitt-m', 'benson-r', 'griffith-j', 'may-l', 'davis-d', 'salisbury-h', 'zufferli-j', 'jones-t', 'reitmeyer-j', 'delainey-d', 'kitchen-l', 'bass-e', 'badeer-r', 'giron-d', 'skilling-j', 'king-j', 'watson-k', 'dickson-s', 'allen-p', 'ruscitti-k', 'linder-e', 'merriss-s', 'ring-r', 'germany-c', 'mcconnell-m', 'mims-thurston-p', 'guzman-m', 'williams-j', 'lewis-a', 'platter-p', 'mccarty-d', 'neal-s', 'storey-g', 'pimenov-v', 'shankman-j', 'sturm-f', 'dasovich-j', 'richey-c', 'quenet-j', 'quigley-d', 'zipper-a', 'campbell-l'}), ('off_balance_df', {'hodge-j', 'kaminski-v', 'lavorato-j', 'weldon-c', 'symes-k', 'mann-k', 'geaccone-t', 'haedicke-m', 'hyatt-k', 'lenhart-m', 'mclaughlin-e', 'steffes-j', 'holst-k', 'donoho-l', 'buy-r', 'brawner-s', 'ermis-f', 'wolfe-j', 'taylor-m', 'parks-j', 'townsend-j', 'donohoe-t', 'rogers-b', 'tycholiz-b', 'swerzbin-m', 'corman-s', 'nemec-g', 'lokey-t', 'arora-h', 'beck-s', 'whalley-g', 'martin-t', 'schwieger-j', 'lucci-p', 'mckay-b', 'shackleton-s', 'maggi-m', 'carson-m', 'fossum-d', 'stepenovitch-j', 'presto-k', 'whalley-l', 'saibi-e', 'cuilla-m', 'blair-l', 'motley-m', 'baughman-d', 'farmer-d', 'ybarbo-p', 'shively-h', 'keavey-p', 'causholli-m', 'grigsby-m', 'arnold-j', 'shapiro-r', 'sanders-r', 'pereira-s', 'lay-k', 'horton-s', 'kean-s', 'smith-m', 'tholt-j', 'stokley-c', 'dorland-c', 'gay-r', 'hayslett-r', 'semperger-c', 'dean-c', 'thomas-p', 'derrick-j', 'williams-w3', 'lokay-m', 'love-p', 'benson-r', 'griffith-j', 'may-l', 'davis-d', 'salisbury-h', 'zufferli-j', 'jones-t', 'reitmeyer-j', 'delainey-d', 'kitchen-l', 'bass-e', 'giron-d', 'skilling-j', 'watson-k', 'ruscitti-k', 'germany-c', 'mcconnell-m', 'mims-thurston-p', 'guzman-m', 'williams-j', 'lewis-a', 'platter-p', 'mccarty-d', 'neal-s', 'storey-g', 'pimenov-v', 'shankman-j', 'sturm-f', 'dasovich-j', 'quenet-j', 'quigley-d', 'campbell-l'}), ('market_to_market_df', {'buy-r', 'sager-e', 'haedicke-m', 'presto-k', 'kaminski-v', 'taylor-m', 'harris-s', 'townsend-j', 'blair-l', 'white-s', 'watson-k'}), ('fraud_df', {'perlingiere-d', 'hodge-j', 'kaminski-v', 'lavorato-j', 'weldon-c', 'symes-k', 'hernandez-j', 'mann-k', 'geaccone-t', 'haedicke-m', 'hyatt-k', 'lenhart-m', 'mclaughlin-e', 'steffes-j', 'holst-k', 'buy-r', 'scholtes-d', 'wolfe-j', 'taylor-m', 'parks-j', 'townsend-j', 'heard-m', 'rogers-b', 'swerzbin-m', 'corman-s', 'stclair-c', 'nemec-g', 'lokey-t', 'arora-h', 'scott-s', 'hain-m', 'beck-s', 'whalley-g', 'martin-t', 'schwieger-j', 'lucci-p', 'mckay-b', 'shackleton-s', 'cash-m', 'sager-e', 'carson-m', 'fossum-d', 'stepenovitch-j', 'presto-k', 'whalley-l', 'saibi-e', 'blair-l', 'forney-j', 'motley-m', 'baughman-d', 'farmer-d', 'ybarbo-p', 'keavey-p', 'fischer-m', 'grigsby-m', 'arnold-j', 'shapiro-r', 'hyvl-d', 'ring-a', 'keiser-k', 'sanders-r', 'pereira-s', 'lay-k', 'horton-s', 'kean-s', 'stokley-c', 'dorland-c', 'hayslett-r', 'thomas-p', 'derrick-j', 'williams-w3', 'lokay-m', 'hendrickson-s', 'love-p', 'ward-k', 'crandell-s', 'white-s', 'griffith-j', 'may-l', 'salisbury-h', 'jones-t', 'kitchen-l', 'bass-e', 'giron-d', 'skilling-j', 'king-j', 'watson-k', 'allen-p', 'ring-r', 'germany-c', 'mcconnell-m', 'mims-thurston-p', 'lewis-a', 'mccarty-d', 'shankman-j', 'campbell-l', 'dasovich-j', 'quigley-d', 'rapp-b'}), ('insider_trading_df', {'keiser-k', 'kitchen-l', 'bass-e', 'lay-k', 'kaminski-v', 'skilling-j', 'kean-s', 'hernandez-j', 'king-j', 'tholt-j', 'mann-k', 'ruscitti-k', 'ring-r', 'germany-c', 'haedicke-m', 'whalley-g', 'hyatt-k', 'martin-t', 'steffes-j', 'mckay-b', 'cash-m', 'buy-r', 'lewis-a', 'scholtes-d', 'mccarty-d', 'williams-w3', 'storey-g', 'taylor-m', 'whalley-l', 'shankman-j', 'blair-l', 'townsend-j', 'dasovich-j', 'baughman-d', 'corman-s', 'arnold-j', 'shapiro-r'})]\n"
     ]
    }
   ],
   "source": [
    "data_files = ['./spe.text', 'off_balance.text', './market_to_market.text', './fraud.text', './insider_trading.text']\n",
    "sets = []\n",
    "\n",
    "for file in data_files:\n",
    "    with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "\n",
    "        text_data = f.readlines()\n",
    "\n",
    "        name_text = split_name_text(text_data)\n",
    "\n",
    "        if file == './SPE.text':\n",
    "            name_text = filter_dict(file, name_text)\n",
    "\n",
    "        to_csv(name_text)\n",
    "\n",
    "        file_name = os.path.basename(file)\n",
    "        dataframe_name = os.path.splitext(file_name)[0] + '_df'\n",
    "        \n",
    "        df = to_pd()\n",
    "        df = drop_dup_names(df)\n",
    "        names2001 = year_check()\n",
    "\n",
    "        df_2001 = to_df_2001(names2001)\n",
    "\n",
    "        completed_names = check_names(df_2001, df)\n",
    "\n",
    "        entry = (dataframe_name, set(completed_names))\n",
    "        \n",
    "        sets.append(entry)\n",
    "\n",
    "print(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2n/vqpzgydx0c98m723225tmz280000gn/T/ipykernel_31234/789293698.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvenn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvenn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Show the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2n/vqpzgydx0c98m723225tmz280000gn/T/ipykernel_31234/789293698.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvenn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvenn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Show the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn3\n",
    "\n",
    "# Create Venn diagram based on the number of sets\n",
    "if len(sets) == 2:\n",
    "    venn2(subsets=[sets[set_name] for set_name in sets], set_labels=sets.keys())\n",
    "elif len(sets) == 3:\n",
    "    venn3(subsets=[sets[set_name] for set_name in sets], set_labels=sets.keys())\n",
    "elif len(sets) == 4:\n",
    "    venn3(subsets=[sets[set_name] for set_name in sets], set_labels=sets.keys())\n",
    "elif len(sets) == 5:\n",
    "    venn3(subsets=[sets[set_name] for set_name in sets], set_labels=sets.keys())\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
